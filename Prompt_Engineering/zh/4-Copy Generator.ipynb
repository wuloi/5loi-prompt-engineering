{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cfdbf4-16a0-4b49-8ec8-146731290429",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af339990-a99d-484a-86e1-68cd5f284f16",
   "metadata": {},
   "source": [
    "# 星辰自行车营销文案生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473856a-e4a0-40f2-9ee5-2aed42e2d0e1",
   "metadata": {},
   "source": [
    "在这个笔记本中，您将构建一个 AI 驱动的营销文案撰写器，能够执行多种生成任务。您将学习如何编辑模型的**系统消息** 来定义其响应生成的职责。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fcef33-9af0-4fbd-a95d-bafcd4345ce4",
   "metadata": {},
   "source": [
    "## 学习目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50e4b0-e588-4f97-8d60-6860827aa997",
   "metadata": {},
   "source": [
    "在完成此笔记本时，您将能够：\n",
    "- 使用 LLaMA-2 执行各种**文本生成** 任务。\n",
    "- 使用**系统上下文** 为 LLaMA-2 模型提供其总体职责的定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c59404a-c8b1-4227-a3f2-da0eeffe3b7d",
   "metadata": {},
   "source": [
    "## 视频演练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d86f5e-b354-4742-b771-4c0f2ede7cb3",
   "metadata": {},
   "source": [
    "执行下面的单元格以加载此笔记本的视频演练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5783c7-0fa8-4787-a3de-93b40aa74dc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://d36m44n9vdbmda.cloudfront.net/assets/s-fx-12-v1/v2/04-copy.mp4\"\n",
    "\n",
    "video_html = f\"\"\"\n",
    "<video controls width=\"640\" height=\"360\">\n",
    "    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(video_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7f877-c256-4808-b29f-0165f66870b7",
   "metadata": {},
   "source": [
    "## 创建 LLaMA-2 管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939afbd-23ca-4db8-b12b-209c224ee4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
    "# model = \"TheBloke/Llama-2-7B-chat-GPTQ\"\n",
    "\n",
    "llama_pipe = pipeline(\"text-generation\", model=model, device_map=\"auto\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be0d3-4ba9-4a89-9db3-f8ec4b311185",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d6710-8530-44e3-b7d8-0899e948bada",
   "metadata": {},
   "source": [
    "在此笔记本中，我们将使用以下函数来支持我们与 LLM 的交互。现在可以随意浏览一下，因为在下面使用时会更详细地介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e3628-7fee-4202-8734-2e8da3adf574",
   "metadata": {},
   "source": [
    "### 生成模型响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda46556-8b36-407d-94d0-1483cb065e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_length=1024, pipe=llama_pipe, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a response to the given prompt using a specified language model pipeline.\n",
    "\n",
    "    This function takes a prompt and passes it to a language model pipeline, such as LLaMA, \n",
    "    to generate a text response. The function is designed to allow customization of the \n",
    "    generation process through various parameters and keyword arguments.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input text prompt to generate a response for.\n",
    "    - max_length (int): The maximum length of the generated response. Default is 1024 tokens.\n",
    "    - pipe (callable): The language model pipeline function used for generation. Default is llama_pipe.\n",
    "    - **kwargs: Additional keyword arguments that are passed to the pipeline function.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated text response from the model, trimmed of leading and trailing whitespace.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    prompt_text = \"Explain the theory of relativity.\"\n",
    "    response = generate(prompt_text, max_length=512, pipe=my_custom_pipeline, temperature=0.7)\n",
    "    print(response)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def_kwargs = dict(return_full_text=False, return_dict=False)\n",
    "    response = pipe(prompt.strip(), max_length=max_length, **kwargs, **def_kwargs)\n",
    "    return response[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e07bb2-1cee-4785-99b9-b67fe2fb5a5d",
   "metadata": {},
   "source": [
    "### 构造提示，可选地使用系统上下文和/或示例\n",
    "｜Costruct Prompt, Optionally With System Context and/or Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c9a4f-570b-4de7-b46c-8aba8a571edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_prompt_with_context(main_prompt, system_context=\"\", conversation_examples=[]):\n",
    "    \"\"\"\n",
    "    Constructs a complete structured prompt for a language model, including optional system context and conversation examples.\n",
    "\n",
    "    This function compiles a prompt that can be directly used for generating responses from a language model. \n",
    "    It creates a structured format that begins with an optional system context message, appends a series of conversational \n",
    "    examples as prior interactions, and ends with the main user prompt. If no system context or conversation examples are provided,\n",
    "    it will return only the main prompt.\n",
    "\n",
    "    Parameters:\n",
    "    - main_prompt (str): The core question or statement for the language model to respond to.\n",
    "    - system_context (str, optional): Additional context or information about the scenario or environment. Defaults to an empty string.\n",
    "    - conversation_examples (list of tuples, optional): Prior exchanges provided as context, where each tuple contains a user message \n",
    "      and a corresponding agent response. Defaults to an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string formatted as a complete prompt ready for language model input. If no system context or examples are provided, returns the main prompt.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    main_prompt = \"I'm looking to improve my dialogue writing skills for my next short story. Any suggestions?\"\n",
    "    system_context = \"User is an aspiring author seeking to enhance dialogue writing techniques.\"\n",
    "    conversation_examples = [\n",
    "        (\"How can dialogue contribute to character development?\", \"Dialogue should reveal character traits and show personal growth over the story arc.\"),\n",
    "        (\"What are some common pitfalls in writing dialogue?\", \"Avoid exposition dumps in dialogue and make sure each character's voice is distinct.\")\n",
    "    ]\n",
    "\n",
    "    full_prompt = construct_prompt_with_context(main_prompt, system_context, conversation_examples)\n",
    "    print(full_prompt)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return the main prompt if no system context or conversation examples are provided\n",
    "    if not system_context and not conversation_examples:\n",
    "        return main_prompt\n",
    "\n",
    "    # Start with the initial part of the prompt including the system context, if provided\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>{system_context}<</SYS>>\\n\" if system_context else \"<s>[INST]\\n\"\n",
    "\n",
    "    # Add each example from the conversation_examples to the prompt\n",
    "    for user_msg, agent_response in conversation_examples:\n",
    "        full_prompt += f\"{user_msg} [/INST] {agent_response} </s><s>[INST]\"\n",
    "\n",
    "    # Add the main user prompt at the end\n",
    "    full_prompt += f\"{main_prompt} [/INST]\"\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47884189-00e6-4c0d-8e5c-edf41411f088",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 星辰自行车数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a27cac-12ac-4f7c-8065-bb541eb82394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bikes = [\n",
    "    {\n",
    "        \"model\": \"Galaxy Rider\",\n",
    "        \"type\": \"Mountain\",\n",
    "        \"features\": {\n",
    "            \"frame\": \"Aluminum alloy\",\n",
    "            \"gears\": \"21-speed Shimano\",\n",
    "            \"brakes\": \"Hydraulic disc\",\n",
    "            \"tires\": \"27.5-inch all-terrain\",\n",
    "            \"suspension\": \"Full, adjustable\",\n",
    "            \"color\": \"Matte black with green accents\"\n",
    "        },\n",
    "        \"usps\": [\"Lightweight frame\", \"Quick gear shift\", \"Durable tires\"],\n",
    "        \"price\": 799.95,\n",
    "        \"internal_id\": \"GR2321\",\n",
    "        \"weight\": \"15.3 kg\",\n",
    "        \"manufacturer_location\": \"Taiwan\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Nebula Navigator\",\n",
    "        \"type\": \"Hybrid\",\n",
    "        \"features\": {\n",
    "            \"frame\": \"Carbon fiber\",\n",
    "            \"gears\": \"18-speed Nexus\",\n",
    "            \"brakes\": \"Mechanical disc\",\n",
    "            \"tires\": \"26-inch city slick\",\n",
    "            \"suspension\": \"Front only\",\n",
    "            \"color\": \"Glossy white\"\n",
    "        },\n",
    "        \"usps\": [\"Sleek design\", \"Efficient on both roads and trails\", \"Ultra-lightweight\"],\n",
    "        \"price\": 649.99,\n",
    "        \"internal_id\": \"NN4120\",\n",
    "        \"weight\": \"13.5 kg\",\n",
    "        \"manufacturer_location\": \"Germany\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Cosmic Comet\",\n",
    "        \"type\": \"Road\",\n",
    "        \"features\": {\n",
    "            \"frame\": \"Titanium\",\n",
    "            \"gears\": \"24-speed Campagnolo\",\n",
    "            \"brakes\": \"Rim brakes\",\n",
    "            \"tires\": \"700C road\",\n",
    "            \"suspension\": \"None\",\n",
    "            \"color\": \"Metallic blue\"\n",
    "        },\n",
    "        \"usps\": [\"Super aerodynamic\", \"High-speed performance\", \"Professional-grade components\"],\n",
    "        \"price\": 1199.50,\n",
    "        \"internal_id\": \"CC5678\",\n",
    "        \"weight\": \"11 kg\",\n",
    "        \"manufacturer_location\": \"Italy\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4dc85-0f8b-4bb1-a41c-f9d6ee3159b9",
   "metadata": {},
   "source": [
    "## 完整的 LLaMA-2 提示模板\n",
    "｜The Full LLaMA-2 Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46532c-53c4-462f-b8dd-69923319d6da",
   "metadata": {},
   "source": [
    "在之前的笔记本中，我们利用 LLaMA-2 的**提示模板（prompt template）** 来支持**少样本学习（few-shot learning）** ，但提到我们正在使用略微修改版本的提示模板。具体来说，我们省略了提示模板的用户消息部分，称为**系统消息（system message）** 、**系统上下文（system context）** 或**系统提示（system prompt）** (我们将交替使用这些术语)。以下是完整的 LLaMA-2 提示模板，包括其**系统上下文** 部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d27794-a34e-4224-a034-072141a3c94a",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "<s>[INST] <<SYS>>\n",
    "{{ system_context }}\n",
    "<</SYS>>\n",
    "\n",
    "{{ user_msg_1 }} [/INST] {{ model_answer_1 }} </s>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a99577-670c-4dc2-863e-ea76b411c7ef",
   "metadata": {},
   "source": [
    "**系统上下文** 是用户/模型交互的用户端的一部分，位于`<<SYS>>`和`<</SYS>>`标签之间。**系统上下文** 是一个初步的陈述或上下文提示，旨在将 AI 模型的响应引导到特定框架或对任务的理解。\n",
    "\n",
    "关于什么属于**系统上下文** 没有硬性规定，但我们应该主要将其视为设置模型的职责，或任何将适用于其所有响应的上下文。\n",
    "\n",
    "以下是 LLaMA-2 聊天模型的默认**系统消息** ，在其指令微调期间使用："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6928fa1-d99a-47af-a69e-23d3c2bac996",
   "metadata": {
    "tags": []
   },
   "source": [
    ">您是一位乐于助人、尊重他人和诚实的助手。始终尽可能提供帮助，同时保持安全。您的答案不应包含任何有害、不道德、种族主义、性别歧视、有毒、危险或非法的內容。请确保您的回复在社会上公正且积极。\n",
    ">如果问题毫无意义或在事实上一致性，请解释原因，而不是回答错误的东西。如果您不知道某个问题的答案，请不要分享虚假信息。\n",
    "\n",
    ">You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    ">If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9428f44-b399-4280-9011-68b08bc251e7",
   "metadata": {},
   "source": [
    "## 设置系统上下文\n",
    "｜Setting the System Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8cb5e-1a77-4156-9b3e-bbfb3eed1b1c",
   "metadata": {},
   "source": [
    "以下`construct_prompt_with_context`函数将帮助我们使用 LLaMA-2**提示模板** 构建具有更新**系统消息** 的提示。此函数还允许我们，如果我们愿意，通过传入 2 元组示例交互列表来执行**少样本学习** ，就像我们在上一节中所做的那样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d623e-8ff3-4142-8d63-93848c5a82c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_prompt_with_context(main_prompt, system_context=\"\", conversation_examples=[]):\n",
    "    \"\"\"\n",
    "    Constructs a complete structured prompt for a language model, including optional system context and conversation examples.\n",
    "\n",
    "    This function compiles a prompt that can be directly used for generating responses from a language model. \n",
    "    It creates a structured format that begins with an optional system context message, appends a series of conversational \n",
    "    examples as prior interactions, and ends with the main user prompt. If no system context or conversation examples are provided,\n",
    "    it will return only the main prompt.\n",
    "\n",
    "    Parameters:\n",
    "    - main_prompt (str): The core question or statement for the language model to respond to.\n",
    "    - system_context (str, optional): Additional context or information about the scenario or environment. Defaults to an empty string.\n",
    "    - conversation_examples (list of tuples, optional): Prior exchanges provided as context, where each tuple contains a user message \n",
    "      and a corresponding agent response. Defaults to an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string formatted as a complete prompt ready for language model input. If no system context or examples are provided, returns the main prompt.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    main_prompt = \"I'm looking to improve my dialogue writing skills for my next short story. Any suggestions?\"\n",
    "    system_context = \"User is an aspiring author seeking to enhance dialogue writing techniques.\"\n",
    "    conversation_examples = [\n",
    "        (\"How can dialogue contribute to character development?\", \"Dialogue should reveal character traits and show personal growth over the story arc.\"),\n",
    "        (\"What are some common pitfalls in writing dialogue?\", \"Avoid exposition dumps in dialogue and make sure each character's voice is distinct.\")\n",
    "    ]\n",
    "\n",
    "    full_prompt = construct_prompt_with_context(main_prompt, system_context, conversation_examples)\n",
    "    print(full_prompt)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return the main prompt if no system context or conversation examples are provided\n",
    "    if not system_context and not conversation_examples:\n",
    "        return main_prompt\n",
    "\n",
    "    # Start with the initial part of the prompt including the system context, if provided\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>{system_context}<</SYS>>\\n\" if system_context else \"<s>[INST]\\n\"\n",
    "\n",
    "    # Add each example from the conversation_examples to the prompt\n",
    "    for user_msg, agent_response in conversation_examples:\n",
    "        full_prompt += f\"{user_msg} [/INST] {agent_response} </s><s>[INST]\"\n",
    "\n",
    "    # Add the main user prompt at the end\n",
    "    full_prompt += f\"{main_prompt} [/INST]\"\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e919d-7f72-4aa6-9234-b5fd7c8baefa",
   "metadata": {},
   "source": [
    "## 星辰自行车营销文案生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb5d20-19bd-4571-b34e-68e8155dad6e",
   "metadata": {},
   "source": [
    "让我们使用我们的 LLaMA-2 模型作为营销文案生成器。对于其任务，我们将提供一个 JSON 对象，其中包含有关我们想要为其撰写文案的星辰自行车模型的相关规格。如果您还没有，请查看上面的“星辰自行车数据”部分以获取`bikes`的定义。\n",
    "\n",
    "我们将从一个简单的提示开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4a56-c930-48cd-8be7-532bcb4162ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Write marketing copy for the following bicycle: {bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9821b-de8d-4081-b208-9d1ee791d98d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4724a9e-1266-4bd8-b0c7-9c29212a4c64",
   "metadata": {},
   "source": [
    "这还不错，并且根据您已经了解的内容，您可能会迭代一个提示来改进模型的响应。但是假设我们希望我们的模型充当营销文案撰写器，可能以各种格式撰写文案，让我们通过提供有关其职责的知识来提供**系统上下文** 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54a453-585a-4e67-9133-e0fb55cb8873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a marketing copy writer for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902c7bb-db2a-46c3-a555-a433c57bbea9",
   "metadata": {},
   "source": [
    "使用我们的`construct_prompt_with_context`函数，我们现在可以创建一个提示，该提示为 LLaMA-2 提示模板设置适当的**系统上下文** 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b7503-8a06-4c50-b9b2-17d2b275daa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_with_system_context = construct_prompt_with_context(prompt, system_context)\n",
    "print(prompt_with_system_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7609f10-f4a4-4d50-9360-d218909c8185",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674e694-8fe3-47bf-b123-5623a81f0dc2",
   "metadata": {},
   "source": [
    "使用我们带有**系统上下文** 的提示，让我们看看我们从模型中得到了什么样的响应。值得一提的是，我们的主要`prompt`（见上文）没有提供任何关于模型需要做什么的说明。我们依靠设置的**系统上下文** 来指导模型的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681bc97-63ae-4d37-8f2b-c18977c7b52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(generate(prompt_with_system_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc9717-dd16-4334-9640-61a8d226f059",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c6b56-90ad-4f8a-8681-5ee828d50065",
   "metadata": {},
   "source": [
    "这还不错，但让我们在**系统上下文** 中更**精确** 地说明模型的职责仅限于生成营销文案，而不是像我们在上一个响应中获得的那样生成任何引导性对话文本，例如`当然！这是 Galaxy Rider 山地自行车的营销文案：`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8265b6-06e3-45ed-9969-56a4f7dcf894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a marketing copy writer for Star Bikes. You only write marketing copy and never any \\\n",
    "leading comments or pieces of conversation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6261046-d977-4aba-95f2-0c52aa6a36c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af91df7-ee21-4240-9cd1-5937262c0d92",
   "metadata": {},
   "source": [
    "这似乎没有帮助。让我们进行迭代。也许如果我们告诉模型它是一台机器，它就不会试图进行类似人类的对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd1d32-3e8f-49a6-9a0f-22e2b89fd672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a non-conversant machine that generates marketing copy in 100 words or less. You work for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f6bd0-9162-4035-809b-6fe273737ce6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c2d4c-ead3-47d4-b6af-0f3b6c375925",
   "metadata": {},
   "source": [
    "好多了！就像所有提示工程一样，开发有效的**系统提示** 通常是一个迭代过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347268b-ce78-48f8-a24b-49cf0d3c244f",
   "metadata": {},
   "source": [
    "## 强制简洁\n",
    "｜Enforce Brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf3681-0133-4d33-b632-d4453dd94f83",
   "metadata": {},
   "source": [
    "让我们假设我们只希望获得约 100 个单词的响应。我们可以更新**系统上下文** 以反映这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959dda4-4196-425c-954f-75c10ff30545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a non-conversant machine that generates marketing copy in 100 words or less. You work for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde70ee8-01da-406e-a6bf-32b51ce522bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c36ba-7434-44d6-bb83-517800944c83",
   "metadata": {},
   "source": [
    "太好了。现在我们已经建立了一个似乎对我们有效的设置，让我们在其他自行车的數據上试一试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75d271-072f-493d-bce2-4f9994b2a844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for bike in bikes[1:]:\n",
    "    print(generate(construct_prompt_with_context(bike, system_context)))\n",
    "    print(\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72596c88-4c23-4cd7-addf-1692c28c6c36",
   "metadata": {},
   "source": [
    "## 练习：生成营销邮件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d517d-65da-4ccf-95ee-a80cbb468544",
   "metadata": {},
   "source": [
    "利用您到目前为止学到的知识，创建一个提示（可能利用其**系统上下文** ）为特定自行车的用户撰写营销邮件。电子邮件应以收件人的姓名称呼收件人。\n",
    "\n",
    "如果您遇到困难，请查看下面的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9392c0-bc95-4b03-b372-ba1fa7c25813",
   "metadata": {},
   "source": [
    "### 您的工作在此处"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8ee94-39b6-40d0-9621-6452ed715014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b2ac353-a873-430b-8a10-c93e45419ae5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256a6e4-fec7-4d4c-80f9-697865ed4e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a non-conversant machine that generates marketing emails in 100 words or less. You work for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Recipient Name: Stella\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada345a-39f1-42d7-a63a-7e97a1317978",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 关键概念回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7532c88-f77e-4fbf-8919-98bd4d53bd85",
   "metadata": {},
   "source": [
    "本笔记本中介绍了以下关键概念：\n",
    "\n",
    "- **系统消息 System Message：** 指令微调模型（fine-tuned models）的提示模板（prompt templates）的一部分，允许用户设置其行为的职责（role）或总体上下文（overarching context）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb5f5f-fb8a-458d-8b2d-14164857164d",
   "metadata": {},
   "source": [
    "## 可选的高级练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff817bde-7bbb-4a88-9a0b-887ca533f702",
   "metadata": {},
   "source": [
    "如果您想超越课程的要求，以下是一些供您尝试的额外开放式练习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf8fdb-7ddc-446e-b530-d25eb8a25069",
   "metadata": {},
   "source": [
    "### 使用 7B 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc567fb7-8364-4c8c-95a1-0a510036fa0c",
   "metadata": {},
   "source": [
    "在笔记本的顶部，在重新启动内核（请参见下面的单元格）之后，取消注释并使用 7B 模型而不是我们演示的 13B 模型。尝试在使用较小（较弱）模型的情况下获得令人满意的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbccb1-bc7e-4b72-9f25-37b797095749",
   "metadata": {},
   "source": [
    "### 实验以找到最佳方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd98e41-ec75-4fc2-b51d-94139083abd8",
   "metadata": {},
   "source": [
    "我们通过结合基本提示的迭代、系统消息的编辑以及提供示例（又称“样本”，shots）来帮助模型，得出了几个有效的提示。哪种方法效果更好，通常更像是一种艺术而不是科学：看看您是否可以通过强调所有这三个“杠杆（levers）”的变化来获得可接受的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20744407-6de1-4ac3-b08e-dc5e75972cb9",
   "metadata": {},
   "source": [
    "### 创建电子邮件生成管道"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2d2a7-dea2-4b9c-a140-80b639e7e0ac",
   "metadata": {},
   "source": [
    "扩展上面练习中的工作，创建一个管道，给定一组收件人，可以为他们每个人生成电子邮件。您可以考虑创建更多内容的合成用户数据，而不仅仅是收件人的姓名，例如他们之前购买或表示感兴趣的自行车、是否已向他们发送过电子邮件等，然后生成与这些详细信息更相关的电子邮件。\n",
    "\n",
    "您还可以考虑在**少样本（few-shot）** 学习的背景下做更多的事情，以特定方式构建电子邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37acb023-5f07-4bb9-8343-c7e3230deea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 重新启动内核\n",
    "｜Restart the Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8ecaf-b860-487f-8b4d-b4dd358fa06f",
   "metadata": {},
   "source": [
    "为了释放下一个笔记本的 GPU 内存，请运行以下单元格以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379dc277-e2f2-4ac3-8972-842ad073edb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c06ba1",
   "metadata": {},
   "source": [
    "# [5LOI DEEP LEARNING INSTITUE](https://5loi.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b01a3",
   "metadata": {},
   "source": [
    "### [AI COMMUNITY](https://www.theforage.cn/community)\n",
    "\n",
    "### [5LOI](https://5loi.com/about_loi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6c0a2-798a-460d-b025-40735e64f6af",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
