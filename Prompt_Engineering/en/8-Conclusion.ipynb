{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542cc5a5-0496-4a04-b803-ff010b1ab6a5",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc9691-32f3-4ade-98ae-8c3079c4ea8d",
   "metadata": {},
   "source": [
    "# Course Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2ad9d-b0d6-4a7e-91e3-025c54226e58",
   "metadata": {},
   "source": [
    "Congratulations on completing *Prompt Engineering with LLaMA-2*! It is our sincere wish that you enjoyed the course, and feel much more capable in your ability to interact with LLMs through a variety of prompt engineering techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda93c0-20a2-47c2-8676-e21a606c2ee1",
   "metadata": {},
   "source": [
    "## Video Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375bfe8-b3a2-4389-970d-e902b48ce0bd",
   "metadata": {},
   "source": [
    "Execute the cell below to load the video walkthrough of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0936fb-6353-4bca-ad6e-666fbd0f0404",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://d36m44n9vdbmda.cloudfront.net/assets/s-fx-12-v1/v2/08-conclusion.mp4\"\n",
    "\n",
    "video_html = f\"\"\"\n",
    "<video controls width=\"640\" height=\"360\">\n",
    "    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(video_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767d1bc-0ca6-4e21-bf9a-90122b3456ec",
   "metadata": {},
   "source": [
    "## Course Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b09fb9-804e-4a27-b134-141b0d7411a1",
   "metadata": {},
   "source": [
    "You covered a lot of ground in this course. Now that you've completed this course you can:\n",
    "\n",
    "- Work **iteratively** to craft prompts that are **specific**, provide **cues** and give the model **\"time to think\"**.\n",
    "- Perform **sentiment analysis** on unstructured text.\n",
    "- Understand the LLaMA-2 **prompt template** and its role in **instruction fine-tuning**.\n",
    "- Provide LLMs with instructive examples using **few-shot learning**.\n",
    "- Use LLMs to generate structured data for potential use in downstream tasks.\n",
    "- Assign a role to the model using **system context** in order to perform a variety of **text generation** tasks.\n",
    "- Use **sampling** and **temperature** to control the randomness of a model's outputs.\n",
    "- Enable **chatbot** functionality with a model, including the ability to retain conversation history.\n",
    "- Create **AI assistants** capable of discussing task-specific details, provided as data.\n",
    "- Generate **synthetic data**.\n",
    "- Work within the contraints of a model's **token limit**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac9efc-1d35-48de-acf4-e1bfebba8491",
   "metadata": {},
   "source": [
    "## Course Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98fa5c-49f8-4835-9fa0-52df9214fb2d",
   "metadata": {},
   "source": [
    "We greatly appreciate your participation in this course, and would love your feedback so we can know what you enjoyed, and how we can improve the course. Please take 2 minutes to complete the [course survey](https://learn.next.courses.nvidia.com/courses/course-v1:DLI+S-FX-12+V1/courseware/258ba24018854cbfb9f7ff5e04b7d6f8/b9163e9fecfa407ba728d85f7ad4a55b/?activate_block_id=block-v1%3ADLI%2BS-FX-12%2BV1%2Btype%40sequential%2Bblock%40b9163e9fecfa407ba728d85f7ad4a55b)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627ddaa-5abe-4669-a3b9-0150948a4bfb",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b4bf7-15c0-4d6d-95a4-eba36b979623",
   "metadata": {},
   "source": [
    "Now that you have a practical set of prompt engineering skills, the following topics will likely be of interest to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e597140-25ea-4344-8163-402abcbc57da",
   "metadata": {},
   "source": [
    "### LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c23c3-1243-473d-b957-ed2b3105896f",
   "metadata": {},
   "source": [
    "\"[LangChain](https://python.langchain.com/docs/get_started/introduction) is a framework for developing applications powered by large language models.\" Free and open source, LangChain ships with an ever-increasing collection of modules and components for working with LLMs.\n",
    "\n",
    "In this course, we intentionally worked directly with Python to create helper functions and classes, and in doing so earned a thorough understanding of core prompt engineering practices. However, LangChain can expedite your future work by providing you with boilerplate code to expedite and expand on the techniques you've learned in this workshop, and also supports a variety of LLM uses that are beyond the scope of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293ab0b-2d8f-45cd-b737-74658d310389",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d44b6-6c82-45c4-9cf1-c58a91e51a78",
   "metadata": {},
   "source": [
    "In this course, we came up against LLM some boundaries of LLM capabilities based on the limitations of the amount of tokens it can process.\n",
    "\n",
    "[Retrieval-Augmented Generation](https://research.ibm.com/blog/retrieval-augmented-generation-RAG) (or RAG) allows an LLM to fetch relevant information from a large corpus of data (like a vector database, such as [FAISS](https://python.langchain.com/docs/integrations/vectorstores/faiss)), and formulate coherent responses based on that retrieved information. This allows the model to \"look up\" vast amounts of information without needing to remember it all in the immediate context (such as its prompt).\n",
    "\n",
    "RAG both largely eliminates the contraints placed on us in prompt engineering from token limits, and also provides a powerful mechanism to make the model aware of information that it may not have been initially trained on.\n",
    "\n",
    "At the time of writing this, the DLI is developing a comprehensive course on building RAG systems. Keep an eye on the DLI catalog for the release of this course towards the beginning of 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdb27f-ad83-4e37-b929-7ee6c9611f1d",
   "metadata": {},
   "source": [
    "### Parameter Efficient Fine Tuning (PEFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a2d22-4d30-4a4e-b90b-8ebfbf203b55",
   "metadata": {},
   "source": [
    "In this course we were able to influence the behavior of our model through prompt engineering. There are however, limitations to the amount of control we have over the model using prompt engineering alone.\n",
    "\n",
    "When many-shot learning is insufficient to elicit the behavior we need from an LLM, either because of the format of the response, or the correctness with regards to domain-specific knowledge, a logical next step is to perform parameter efficient fine tuning of PEFT.\n",
    "\n",
    "PEFT techniques allow task-specific adaptations to LLMs with relatively few (hundreds to thousands) training examples and reduced computational cost compared to full model fine tuning. PEFT is a way to give the model a \"head start\" on a particular types of task, without retraining the entire model.\n",
    "\n",
    "At the time of writing this, the DLI is developing a multiple comprehensive courses on PEFT techniques. Keep an eye on the DLI catalog for the release of these materials towards the end of 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452db2d-0bbc-4a10-af7e-02c8cc4c3a2b",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
